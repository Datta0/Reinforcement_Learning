{"cells":[{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1453,"status":"ok","timestamp":1656135570281,"user":{"displayName":"Venkata Datta Sai Nimmaturi","userId":"09700045309629374931"},"user_tz":-330},"id":"iyzd5J8Cofdj"},"outputs":[],"source":["import numpy as np\n","import random\n","import os"]},{"cell_type":"markdown","metadata":{"id":"9eUc6HRTmYqD"},"source":["#Pacman"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1656135571788,"user":{"displayName":"Venkata Datta Sai Nimmaturi","userId":"09700045309629374931"},"user_tz":-330},"id":"sD0S7SF3oozD"},"outputs":[],"source":["class Pacman:\n","\n","    def __init__(self, grid_size, num_food_pellets):\n","        self.grid_size = grid_size\n","        self.num_food_pellets = num_food_pellets\n","        # Directions, Up Down Right Left and stay\n","        self.action_space = [(1, 0), (-1, 0), (0, 1), (0, -1), (0, 0)]\n","        self.init()\n","\n","    def init(self,):\n","        # 1 to self.grid_size-1 cuz the borders are walls\n","        locs = [(i, j) for i in range(1, self.grid_size-1)\n","                for j in range(1, self.grid_size-1)]\n","        random.shuffle(locs)\n","\n","        self.pacman = locs.pop()  # set pacman's location\n","        self.food_pellets = set()\n","\n","        self.set_food()\n","\n","        self.create_ghost()\n","        self.reward = 0\n","        self.score = 0\n","\n","    def set_food(self,):\n","        (r, c) = self.pacman  # row and col of pacman's location\n","\n","        valid_locs = [(i, j) for i in range(1, self.grid_size-1) for j in range(\n","            1, self.grid_size-1) if (i, j) != (r, c)]  # Initialise food pellet positions randomly\n","        random.shuffle(valid_locs)\n","        for i in range(self.num_food_pellets):\n","            self.food_pellets.add(valid_locs.pop())\n","\n","        self.food_pellets_left = self.num_food_pellets\n","\n","    def create_ghost(self,):\n","        (r, c) = self.pacman\n","        # Initialize the ghost in same column as pacman\n","        if r != 1:\n","            self.ghost = (1, c)\n","        else:\n","            self.ghost = (self.grid_size-2, c)\n","        self.ghost_action = random.choice(self.action_space)\n","\n","    def display(self,):\n","        print(\"Current score: {}\".format(self.score))\n","\n","        for r in range(self.grid_size):\n","            for c in range(self.grid_size):\n","                if (r, c) == self.pacman:\n","                    print('P', end='')\n","                elif (r, c) == self.ghost:\n","                    print('G', end='')\n","                elif (r, c) in self.food_pellets:\n","                    print('o', end='')\n","                elif self.is_boundary((r, c)):\n","                    print('*', end='')\n","                else:\n","                    print(' ', end='')\n","            print('')\n","\n","    def is_end(self,):\n","        if self.reward == -100:\n","            return True\n","        return False\n","\n","    def is_boundary(self, pos):\n","        if pos[0] == 0 or pos[0] == self.grid_size-1 or pos[1] == 0 or pos[1] == self.grid_size-1:\n","            return True\n","\n","    def step(self, action):\n","        # save current positions of pacman and ghost\n","        pacman, ghost = self.pacman, self.ghost\n","        # print('pacman {} action {} ghost {}'.format(pacman,action,ghost))\n","        # Move pacman acc to action\n","        (px, py) = self.action_space[action]\n","        (r, c) = self.pacman\n","        self.pacman = (r+px, c+py)\n","\n","        # Move ghost acc to ghost_action ie random\n","        (gx, gy) = self.ghost_action\n","        (gr, gc) = self.ghost\n","        self.ghost = (gr+gx, gc+gy)\n","\n","        if self.is_boundary(self.ghost):\n","            self.create_ghost()\n","\n","        # If both at same place or both crossed through the other this move or pacman hits boundary, end game\n","        if self.pacman == self.ghost or (pacman, self.ghost) == (ghost, self.pacman) or self.is_boundary(self.pacman):\n","            self.reward = -100\n","        elif self.pacman in self.food_pellets:\n","            self.food_pellets_left -= 1\n","            self.food_pellets.remove(self.pacman)\n","            self.reward = 10\n","            if self.food_pellets_left == 0:\n","                self.set_food()\n","        else:\n","            self.reward = 0\n","        self.ghost_action = random.choice(self.action_space)\n","        self.score += self.reward\n"]},{"cell_type":"markdown","metadata":{"id":"G5GKrTUfmavS"},"source":["# SARSA Agent"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1656135571788,"user":{"displayName":"Venkata Datta Sai Nimmaturi","userId":"09700045309629374931"},"user_tz":-330},"id":"9zLiJMxIyxtx"},"outputs":[],"source":["class sarsa:\n","\n","    def __init__(self,game,num_episodes, alpha, epsilon, gamma):\n","        self.num_episodes = num_episodes\n","        self.alpha = alpha\n","        self.epsilon = epsilon\n","        self.gamma = gamma\n","        self.game = game\n","        self.Q = {}\n","\n","    def choose_action_epsilon_greedy(self,state):\n","\n","        if state not in self.Q:\n","            return random.randint(0,len(self.game.action_space)-1)\n","        else:\n","            greedy_action_index = np.argmax(self.Q[state])\n","            l = len(self.game.action_space)\n","            probabilities = [1.0 - self.epsilon*(1-(1/l))] + [self.epsilon/l for i in range(l-1)]\n","            action_choices = [greedy_action_index] + [x for x in range(l) if x!=greedy_action_index]\n","            # print('probabilities {} action_choices {}'.format(probabilities,action_choices))\n","            action = np.random.choice(action_choices, p=probabilities)\n","\n","            return action\n","    \n","    def checkQ(self,state):\n","        if state not in self.Q:\n","            self.Q[state] = np.zeros(len(self.game.action_space))\n","    \n","    def get_state(self,pacman,ghost,food_pellets):\n","        return '{}, {}, {}'.format(pacman, ghost, sorted(food_pellets))\n","    \n","    def train_agent(self,):\n","\n","        episode_steps = 0\n","        total_steps = 0\n","\n","        for episode in range(self.num_episodes):\n","            self.game.init()\n","            \n","            pacman = self.game.pacman\n","            ghost = self.game.ghost\n","            food = self.game.food_pellets\n","            state = self.get_state(pacman, ghost, food)\n","\n","            action = self.choose_action_epsilon_greedy(state)\n","            self.checkQ(state)\n","            total_steps += episode_steps\n","            episode_steps = 0\n","\n","            while True:\n","                episode_steps += 1\n","                self.game.step(action)\n","                reward = self.game.reward\n","\n","                next_pacman = self.game.pacman\n","                next_ghost = self.game.ghost\n","                next_food_pellets = self.game.food_pellets\n","                next_state = self.get_state(next_pacman, next_ghost, next_food_pellets)\n","    \n","                next_action = self.choose_action_epsilon_greedy(next_state)\n","                self.checkQ(next_state)\n","                #SARSA\n","                # print('state {} action {} next {} na {}'.format(state,action,next_state,next_action))\n","                # print(self.Q)\n","                self.Q[state][action] = self.Q[state][action] + self.alpha * (reward + self.gamma*self.Q[next_state][next_action] - self.Q[state][action] )\n","\n","                state = next_state\n","                action = next_action\n","\n","                if self.game.is_end():\n","                    break\n","            if episode!=0 and episode%1000==0:\n","                print('Episode: {} Steps this episode: {} Average steps: {}'.format(episode, episode_steps, round(total_steps/episode,2)))\n","                if episode%10000==0:\n","                    print('-----------------------------------------------------------------------')\n","        \n","    def test_agent(self,):\n","\n","        self.game.init()\n","        self.game.display()\n","\n","        while True:\n","            \n","            pacman = self.game.pacman\n","            ghost = self.game.ghost\n","            food = self.game.food_pellets\n","            state = self.get_state(pacman, ghost, food)\n","\n","            action = self.choose_action_epsilon_greedy(state)\n","            self.game.step(action)\n","            self.game.display()\n","\n","            if self.game.is_end():\n","                break"]},{"cell_type":"markdown","metadata":{"id":"ehJ0kAj-mfwC"},"source":["# Q Function"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":1439,"status":"ok","timestamp":1656136011138,"user":{"displayName":"Venkata Datta Sai Nimmaturi","userId":"09700045309629374931"},"user_tz":-330},"id":"TZIgUrqZGHqz"},"outputs":[],"source":["class q_func:\n","\n","    def __init__(self,game,num_episodes, alpha, epsilon, gamma):\n","        self.num_episodes = num_episodes\n","        self.alpha = alpha\n","        self.epsilon = epsilon\n","        self.gamma = gamma\n","        self.game = game\n","        self.Q = {}\n","\n","    def choose_action_epsilon_greedy(self,state):\n","\n","        if state not in self.Q:\n","            return random.randint(0,len(self.game.action_space)-1)\n","        else:\n","            greedy_action_index = np.argmax(self.Q[state])\n","            l = len(self.game.action_space)\n","            probabilities = [1.0 - self.epsilon*(1-(1/l))] + [self.epsilon/l for i in range(l-1)]\n","            action_choices = [greedy_action_index] + [x for x in range(l) if x!=greedy_action_index]\n","            # print('probabilities {} action_choices {}'.format(probabilities,action_choices))\n","            action = np.random.choice(action_choices, p=probabilities)\n","\n","            return action\n","    \n","    def checkQ(self,state):\n","        if state not in self.Q:\n","            self.Q[state] = np.zeros(len(self.game.action_space))\n","    \n","    def get_state(self,pacman,ghost,food_pellets):\n","        return '{}, {}, {}'.format(pacman, ghost, sorted(food_pellets))\n","    \n","    def train_agent(self,):\n","\n","        episode_steps = 0\n","        total_steps = 0\n","\n","        for episode in range(self.num_episodes):\n","            self.game.init()\n","            \n","            pacman = self.game.pacman\n","            ghost = self.game.ghost\n","            food = self.game.food_pellets\n","            state = self.get_state(pacman, ghost, food)\n","\n","            action = self.choose_action_epsilon_greedy(state)\n","            self.checkQ(state)\n","            total_steps += episode_steps\n","            episode_steps = 0\n","\n","            while True:\n","                episode_steps += 1\n","                self.game.step(action)\n","                reward = self.game.reward\n","\n","                next_pacman = self.game.pacman\n","                next_ghost = self.game.ghost\n","                next_food_pellets = self.game.food_pellets\n","                next_state = self.get_state(next_pacman, next_ghost, next_food_pellets)\n","    \n","                next_action = self.choose_action_epsilon_greedy(next_state)\n","                self.checkQ(next_state)\n","                #QFUNC\n","                # print('state {} action {} next {} na {}'.format(state,action,next_state,next_action))\n","                # print(self.Q)\n","                self.Q[state][action] = self.Q[state][action] + self.alpha * (reward + self.gamma*np.max(self.Q[next_state]) - self.Q[state][action] )\n","\n","                state = next_state\n","                action = next_action\n","\n","                if self.game.is_end():\n","                    break\n","            if episode!=0 and episode%1000==0:\n","                print('Episode: {} Steps this episode: {} Average steps: {}'.format(episode, episode_steps, round(total_steps/episode,2)))\n","                if episode%10000==0:\n","                    print('-----------------------------------------------------------------------')\n","        \n","    def test_agent(self,):\n","\n","        self.game.init()\n","        self.game.display()\n","\n","        while True:\n","            \n","            pacman = self.game.pacman\n","            ghost = self.game.ghost\n","            food = self.game.food_pellets\n","            state = self.get_state(pacman, ghost, food)\n","\n","            action = self.choose_action_epsilon_greedy(state)\n","            self.game.step(action)\n","            self.game.display()\n","\n","            if self.game.is_end():\n","                break"]},{"cell_type":"markdown","metadata":{"id":"LuGfYFa6mkpD"},"source":["# Train"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":298360,"status":"ok","timestamp":1656135873044,"user":{"displayName":"Venkata Datta Sai Nimmaturi","userId":"09700045309629374931"},"user_tz":-330},"id":"ApfbqHk7GH8v","outputId":"0f9518c3-3b2b-46de-9f25-505c93161f92"},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode: 1000 Steps this episode: 1 Average steps: 5.73\n","Episode: 2000 Steps this episode: 1 Average steps: 9.99\n","Episode: 3000 Steps this episode: 5 Average steps: 13.16\n","Episode: 4000 Steps this episode: 31 Average steps: 15.31\n","Episode: 5000 Steps this episode: 26 Average steps: 17.1\n","Episode: 6000 Steps this episode: 17 Average steps: 18.64\n","Episode: 7000 Steps this episode: 57 Average steps: 20.15\n","Episode: 8000 Steps this episode: 20 Average steps: 21.49\n","Episode: 9000 Steps this episode: 41 Average steps: 22.58\n","Episode: 10000 Steps this episode: 9 Average steps: 23.37\n","-----------------------------------------------------------------------\n","Episode: 11000 Steps this episode: 23 Average steps: 24.13\n","Episode: 12000 Steps this episode: 24 Average steps: 24.82\n","Episode: 13000 Steps this episode: 34 Average steps: 25.46\n","Episode: 14000 Steps this episode: 31 Average steps: 25.98\n","Episode: 15000 Steps this episode: 27 Average steps: 26.49\n","Episode: 16000 Steps this episode: 23 Average steps: 27.03\n","Episode: 17000 Steps this episode: 156 Average steps: 27.44\n","Episode: 18000 Steps this episode: 8 Average steps: 27.84\n","Episode: 19000 Steps this episode: 9 Average steps: 28.22\n","Episode: 20000 Steps this episode: 20 Average steps: 28.45\n","-----------------------------------------------------------------------\n","Episode: 21000 Steps this episode: 14 Average steps: 28.79\n","Episode: 22000 Steps this episode: 2 Average steps: 29.01\n","Episode: 23000 Steps this episode: 12 Average steps: 29.23\n","Episode: 24000 Steps this episode: 4 Average steps: 29.44\n","Episode: 25000 Steps this episode: 43 Average steps: 29.64\n","Episode: 26000 Steps this episode: 6 Average steps: 29.72\n","Episode: 27000 Steps this episode: 8 Average steps: 29.93\n","Episode: 28000 Steps this episode: 48 Average steps: 30.12\n","Episode: 29000 Steps this episode: 59 Average steps: 30.26\n","Episode: 30000 Steps this episode: 12 Average steps: 30.38\n","-----------------------------------------------------------------------\n","Episode: 31000 Steps this episode: 4 Average steps: 30.5\n","Episode: 32000 Steps this episode: 28 Average steps: 30.61\n","Episode: 33000 Steps this episode: 4 Average steps: 30.83\n","Episode: 34000 Steps this episode: 59 Average steps: 30.94\n","Episode: 35000 Steps this episode: 7 Average steps: 31.04\n","Episode: 36000 Steps this episode: 7 Average steps: 31.12\n","Episode: 37000 Steps this episode: 207 Average steps: 31.21\n","Episode: 38000 Steps this episode: 71 Average steps: 31.24\n","Episode: 39000 Steps this episode: 6 Average steps: 31.28\n","Episode: 40000 Steps this episode: 45 Average steps: 31.34\n","-----------------------------------------------------------------------\n","Episode: 41000 Steps this episode: 61 Average steps: 31.4\n","Episode: 42000 Steps this episode: 32 Average steps: 31.47\n","Episode: 43000 Steps this episode: 7 Average steps: 31.5\n","Episode: 44000 Steps this episode: 12 Average steps: 31.53\n","Episode: 45000 Steps this episode: 125 Average steps: 31.59\n","Episode: 46000 Steps this episode: 64 Average steps: 31.66\n","Episode: 47000 Steps this episode: 106 Average steps: 31.73\n","Episode: 48000 Steps this episode: 15 Average steps: 31.77\n","Episode: 49000 Steps this episode: 10 Average steps: 31.77\n","Episode: 50000 Steps this episode: 33 Average steps: 31.81\n","-----------------------------------------------------------------------\n","Episode: 51000 Steps this episode: 36 Average steps: 31.87\n","Episode: 52000 Steps this episode: 29 Average steps: 31.91\n","Episode: 53000 Steps this episode: 34 Average steps: 31.96\n","Episode: 54000 Steps this episode: 10 Average steps: 31.99\n","Episode: 55000 Steps this episode: 51 Average steps: 32.05\n","Episode: 56000 Steps this episode: 1 Average steps: 32.08\n","Episode: 57000 Steps this episode: 104 Average steps: 32.14\n","Episode: 58000 Steps this episode: 39 Average steps: 32.18\n","Episode: 59000 Steps this episode: 22 Average steps: 32.22\n","Episode: 60000 Steps this episode: 111 Average steps: 32.25\n","-----------------------------------------------------------------------\n","Episode: 61000 Steps this episode: 31 Average steps: 32.32\n","Episode: 62000 Steps this episode: 23 Average steps: 32.35\n","Episode: 63000 Steps this episode: 11 Average steps: 32.39\n","Episode: 64000 Steps this episode: 114 Average steps: 32.46\n","Episode: 65000 Steps this episode: 46 Average steps: 32.5\n","Episode: 66000 Steps this episode: 39 Average steps: 32.54\n","Episode: 67000 Steps this episode: 55 Average steps: 32.55\n","Episode: 68000 Steps this episode: 73 Average steps: 32.59\n","Episode: 69000 Steps this episode: 13 Average steps: 32.6\n","Episode: 70000 Steps this episode: 134 Average steps: 32.63\n","-----------------------------------------------------------------------\n","Episode: 71000 Steps this episode: 41 Average steps: 32.65\n","Episode: 72000 Steps this episode: 10 Average steps: 32.67\n","Episode: 73000 Steps this episode: 18 Average steps: 32.7\n","Episode: 74000 Steps this episode: 33 Average steps: 32.73\n","Episode: 75000 Steps this episode: 28 Average steps: 32.78\n","Episode: 76000 Steps this episode: 11 Average steps: 32.79\n","Episode: 77000 Steps this episode: 55 Average steps: 32.83\n","Episode: 78000 Steps this episode: 5 Average steps: 32.87\n","Episode: 79000 Steps this episode: 1 Average steps: 32.9\n","Episode: 80000 Steps this episode: 30 Average steps: 32.94\n","-----------------------------------------------------------------------\n","Episode: 81000 Steps this episode: 4 Average steps: 32.95\n","Episode: 82000 Steps this episode: 2 Average steps: 32.98\n","Episode: 83000 Steps this episode: 131 Average steps: 33.01\n","Episode: 84000 Steps this episode: 19 Average steps: 33.01\n","Episode: 85000 Steps this episode: 42 Average steps: 33.03\n","Episode: 86000 Steps this episode: 19 Average steps: 33.09\n","Episode: 87000 Steps this episode: 38 Average steps: 33.12\n","Episode: 88000 Steps this episode: 25 Average steps: 33.13\n","Episode: 89000 Steps this episode: 6 Average steps: 33.14\n","Episode: 90000 Steps this episode: 42 Average steps: 33.18\n","-----------------------------------------------------------------------\n","Episode: 91000 Steps this episode: 4 Average steps: 33.22\n","Episode: 92000 Steps this episode: 28 Average steps: 33.23\n","Episode: 93000 Steps this episode: 86 Average steps: 33.24\n","Episode: 94000 Steps this episode: 3 Average steps: 33.26\n","Episode: 95000 Steps this episode: 39 Average steps: 33.29\n","Episode: 96000 Steps this episode: 6 Average steps: 33.31\n","Episode: 97000 Steps this episode: 26 Average steps: 33.31\n","Episode: 98000 Steps this episode: 15 Average steps: 33.32\n","Episode: 99000 Steps this episode: 42 Average steps: 33.34\n"]}],"source":["pacman_game = Pacman(grid_size = 5, num_food_pellets = 2)\n","agentQ = q_func(pacman_game, num_episodes = 100000, epsilon = 0.1, gamma = 0.8, alpha = 0.1)\n","agentQ.train_agent()"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":358,"status":"ok","timestamp":1656136030580,"user":{"displayName":"Venkata Datta Sai Nimmaturi","userId":"09700045309629374931"},"user_tz":-330},"id":"ulxyevn8X0g8","outputId":"6ca3e122-b23c-4e8e-ff52-99833bbf9871"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current score: 0\n","*****\n","*P o*\n","*   *\n","*G o*\n","*****\n","Current score: 0\n","*****\n","*P o*\n","*   *\n","*G o*\n","*****\n"]}],"source":["agentQ = q_func(pacman_game, num_episodes = 100000, epsilon = 0.1, gamma = 0.8, alpha = 0.1)\n","agentQ.test_agent()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":280884,"status":"ok","timestamp":1656132364355,"user":{"displayName":"Venkata Datta Sai Nimmaturi","userId":"09700045309629374931"},"user_tz":-330},"id":"2wCeYIMi7vz0","outputId":"4f3133cd-6da4-4206-f06a-feedff95dd25"},"outputs":[{"name":"stdout","output_type":"stream","text":["Episode: 1000 Steps this episode: 3 Average steps: 5.23\n","Episode: 2000 Steps this episode: 7 Average steps: 7.47\n","Episode: 3000 Steps this episode: 66 Average steps: 10.15\n","Episode: 4000 Steps this episode: 85 Average steps: 12.88\n","Episode: 5000 Steps this episode: 37 Average steps: 15.12\n","Episode: 6000 Steps this episode: 10 Average steps: 17.25\n","Episode: 7000 Steps this episode: 5 Average steps: 18.77\n","Episode: 8000 Steps this episode: 55 Average steps: 20.33\n","Episode: 9000 Steps this episode: 32 Average steps: 21.68\n","Episode: 10000 Steps this episode: 76 Average steps: 22.84\n","-----------------------------------------------------------------------\n","Episode: 11000 Steps this episode: 13 Average steps: 23.76\n","Episode: 12000 Steps this episode: 5 Average steps: 24.67\n","Episode: 13000 Steps this episode: 71 Average steps: 25.44\n","Episode: 14000 Steps this episode: 29 Average steps: 26.31\n","Episode: 15000 Steps this episode: 11 Average steps: 26.83\n","Episode: 16000 Steps this episode: 31 Average steps: 27.33\n","Episode: 17000 Steps this episode: 12 Average steps: 27.76\n","Episode: 18000 Steps this episode: 19 Average steps: 28.03\n","Episode: 19000 Steps this episode: 6 Average steps: 28.39\n","Episode: 20000 Steps this episode: 141 Average steps: 28.72\n","-----------------------------------------------------------------------\n","Episode: 21000 Steps this episode: 3 Average steps: 29.03\n","Episode: 22000 Steps this episode: 8 Average steps: 29.29\n","Episode: 23000 Steps this episode: 7 Average steps: 29.59\n","Episode: 24000 Steps this episode: 32 Average steps: 29.82\n","Episode: 25000 Steps this episode: 30 Average steps: 30.03\n","Episode: 26000 Steps this episode: 42 Average steps: 30.21\n","Episode: 27000 Steps this episode: 25 Average steps: 30.39\n","Episode: 28000 Steps this episode: 25 Average steps: 30.54\n","Episode: 29000 Steps this episode: 28 Average steps: 30.61\n","Episode: 30000 Steps this episode: 87 Average steps: 30.8\n","-----------------------------------------------------------------------\n","Episode: 31000 Steps this episode: 9 Average steps: 30.9\n","Episode: 32000 Steps this episode: 13 Average steps: 31.01\n","Episode: 33000 Steps this episode: 49 Average steps: 31.15\n","Episode: 34000 Steps this episode: 54 Average steps: 31.22\n","Episode: 35000 Steps this episode: 7 Average steps: 31.36\n","Episode: 36000 Steps this episode: 25 Average steps: 31.46\n","Episode: 37000 Steps this episode: 9 Average steps: 31.6\n","Episode: 38000 Steps this episode: 6 Average steps: 31.66\n","Episode: 39000 Steps this episode: 52 Average steps: 31.73\n","Episode: 40000 Steps this episode: 21 Average steps: 31.82\n","-----------------------------------------------------------------------\n","Episode: 41000 Steps this episode: 20 Average steps: 31.91\n","Episode: 42000 Steps this episode: 15 Average steps: 31.95\n","Episode: 43000 Steps this episode: 39 Average steps: 31.99\n","Episode: 44000 Steps this episode: 32 Average steps: 32.12\n","Episode: 45000 Steps this episode: 111 Average steps: 32.14\n","Episode: 46000 Steps this episode: 3 Average steps: 32.19\n","Episode: 47000 Steps this episode: 1 Average steps: 32.23\n","Episode: 48000 Steps this episode: 155 Average steps: 32.29\n","Episode: 49000 Steps this episode: 3 Average steps: 32.32\n","Episode: 50000 Steps this episode: 41 Average steps: 32.4\n","-----------------------------------------------------------------------\n","Episode: 51000 Steps this episode: 1 Average steps: 32.44\n","Episode: 52000 Steps this episode: 32 Average steps: 32.47\n","Episode: 53000 Steps this episode: 27 Average steps: 32.5\n","Episode: 54000 Steps this episode: 10 Average steps: 32.58\n","Episode: 55000 Steps this episode: 28 Average steps: 32.69\n","Episode: 56000 Steps this episode: 31 Average steps: 32.77\n","Episode: 57000 Steps this episode: 53 Average steps: 32.83\n","Episode: 58000 Steps this episode: 56 Average steps: 32.85\n","Episode: 59000 Steps this episode: 16 Average steps: 32.87\n","Episode: 60000 Steps this episode: 24 Average steps: 32.93\n","-----------------------------------------------------------------------\n","Episode: 61000 Steps this episode: 6 Average steps: 32.99\n","Episode: 62000 Steps this episode: 19 Average steps: 33.04\n","Episode: 63000 Steps this episode: 17 Average steps: 33.09\n","Episode: 64000 Steps this episode: 34 Average steps: 33.12\n","Episode: 65000 Steps this episode: 42 Average steps: 33.16\n","Episode: 66000 Steps this episode: 33 Average steps: 33.16\n","Episode: 67000 Steps this episode: 4 Average steps: 33.18\n","Episode: 68000 Steps this episode: 8 Average steps: 33.2\n","Episode: 69000 Steps this episode: 26 Average steps: 33.23\n","Episode: 70000 Steps this episode: 8 Average steps: 33.27\n","-----------------------------------------------------------------------\n","Episode: 71000 Steps this episode: 32 Average steps: 33.3\n","Episode: 72000 Steps this episode: 82 Average steps: 33.37\n","Episode: 73000 Steps this episode: 23 Average steps: 33.41\n","Episode: 74000 Steps this episode: 24 Average steps: 33.44\n","Episode: 75000 Steps this episode: 18 Average steps: 33.49\n","Episode: 76000 Steps this episode: 1 Average steps: 33.57\n","Episode: 77000 Steps this episode: 23 Average steps: 33.58\n","Episode: 78000 Steps this episode: 1 Average steps: 33.62\n","Episode: 79000 Steps this episode: 11 Average steps: 33.65\n","Episode: 80000 Steps this episode: 151 Average steps: 33.7\n","-----------------------------------------------------------------------\n","Episode: 81000 Steps this episode: 2 Average steps: 33.76\n","Episode: 82000 Steps this episode: 3 Average steps: 33.77\n","Episode: 83000 Steps this episode: 1 Average steps: 33.81\n","Episode: 84000 Steps this episode: 53 Average steps: 33.83\n","Episode: 85000 Steps this episode: 10 Average steps: 33.82\n","Episode: 86000 Steps this episode: 25 Average steps: 33.87\n","Episode: 87000 Steps this episode: 2 Average steps: 33.9\n","Episode: 88000 Steps this episode: 12 Average steps: 33.92\n","Episode: 89000 Steps this episode: 27 Average steps: 33.95\n","Episode: 90000 Steps this episode: 28 Average steps: 33.95\n","-----------------------------------------------------------------------\n","Episode: 91000 Steps this episode: 32 Average steps: 33.97\n","Episode: 92000 Steps this episode: 5 Average steps: 34.0\n","Episode: 93000 Steps this episode: 2 Average steps: 34.04\n","Episode: 94000 Steps this episode: 12 Average steps: 34.04\n","Episode: 95000 Steps this episode: 8 Average steps: 34.04\n","Episode: 96000 Steps this episode: 8 Average steps: 34.07\n","Episode: 97000 Steps this episode: 44 Average steps: 34.11\n","Episode: 98000 Steps this episode: 30 Average steps: 34.15\n","Episode: 99000 Steps this episode: 33 Average steps: 34.18\n"]}],"source":["pacman_game = Pacman(grid_size = 5, num_food_pellets = 2)\n","sarsa_agent = sarsa(pacman_game, num_episodes = 100000, epsilon = 0.1, gamma = 0.8, alpha = 0.1)\n","sarsa_agent.train_agent()"]},{"cell_type":"markdown","metadata":{"id":"icVdf8ESmmtq"},"source":["# Test"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1656132364357,"user":{"displayName":"Venkata Datta Sai Nimmaturi","userId":"09700045309629374931"},"user_tz":-330},"id":"bjaeSI_2JJ3B","outputId":"d6764d41-025d-4c5d-8042-91a4d837880c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current score: 0\n","*****\n","*  P*\n","*   *\n","*o G*\n","*****\n","Current score: 0\n","*****\n","*  P*\n","*   *\n","*o G*\n","*****\n","Current score: 0\n","*****\n","* P *\n","*  G*\n","*o o*\n","*****\n","Current score: 0\n","*****\n","*P  *\n","*   *\n","*o G*\n","*****\n","Current score: 0\n","*****\n","*G  *\n","*P  *\n","*o o*\n","*****\n","Current score: 10\n","*****\n","* G *\n","*   *\n","*P o*\n","*****\n","Current score: 10\n","*****\n","*  G*\n","*   *\n","* Po*\n","*****\n","Current score: 20\n","*****\n","*   *\n","* oG*\n","* oP*\n","*****\n","Current score: 30\n","*****\n","*   *\n","* oG*\n","* P *\n","*****\n","Current score: 30\n","*****\n","*   *\n","* oG*\n","* P *\n","*****\n","Current score: 30\n","*****\n","*   *\n","* G *\n","* P *\n","*****\n","Current score: 30\n","*****\n","*   *\n","* o *\n","*PG *\n","*****\n","Current score: 30\n","*****\n","*   *\n","*Po *\n","* G *\n","*****\n","Current score: 30\n","*****\n","*   *\n","*Po *\n","*G  *\n","*****\n","Current score: 40\n","*****\n","*   *\n","*oP *\n","*G  *\n","*****\n","Current score: 40\n","*****\n","*   *\n","*o P*\n","*oG *\n","*****\n","Current score: 40\n","*****\n","*  P*\n","*o  *\n","*G  *\n","*****\n"]}],"source":["agentQ.test_agent()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1656132364357,"user":{"displayName":"Venkata Datta Sai Nimmaturi","userId":"09700045309629374931"},"user_tz":-330},"id":"wbNSRzbd8ED_","outputId":"0e59ceee-8724-4af0-a8c5-6fc26abea187"},"outputs":[{"name":"stdout","output_type":"stream","text":["Current score: 0\n","*****\n","*G o*\n","*Po *\n","*   *\n","*****\n","Current score: 0\n","*****\n","*G o*\n","*Po *\n","*   *\n","*****\n","Current score: 0\n","*****\n","* Go*\n","* o *\n","*P  *\n","*****\n","Current score: 0\n","*****\n","*  o*\n","* G *\n","* P *\n","*****\n","Current score: 0\n","*****\n","*  o*\n","*Go *\n","*  P*\n","*****\n","Current score: 0\n","*****\n","*G o*\n","* oP*\n","*   *\n","*****\n","Current score: 0\n","*****\n","* Go*\n","* oP*\n","*   *\n","*****\n","Current score: 0\n","*****\n","*  G*\n","* oP*\n","*   *\n","*****\n","Current score: 10\n","*****\n","* Go*\n","* P *\n","*   *\n","*****\n","Current score: 10\n","*****\n","*  o*\n","* GP*\n","*   *\n","*****\n","Current score: 20\n","*****\n","* GP*\n","*  o*\n","* o *\n","*****\n","Current score: 30\n","*****\n","*G  *\n","*  P*\n","* o *\n","*****\n","Current score: 30\n","*****\n","*G  *\n","* P *\n","* o *\n","*****\n","Current score: 30\n","*****\n","*G  *\n","* P *\n","* o *\n","*****\n","Current score: 30\n","*****\n","*   *\n","*GP *\n","* o *\n","*****\n","Current score: 40\n","*****\n","*   *\n","*oG *\n","* P *\n","*****\n","Current score: 40\n","*****\n","*   *\n","*oG *\n","*P  *\n","*****\n","Current score: 40\n","*****\n","* G *\n","*oo *\n","*P  *\n","*****\n","Current score: 50\n","*****\n","*G  *\n","*Po *\n","*   *\n","*****\n","Current score: 60\n","*****\n","* G *\n","* P *\n","* o *\n","*****\n","Current score: 70\n","*****\n","* o *\n","* G *\n","* P *\n","*****\n","Current score: 70\n","*****\n","* o *\n","*G  *\n","*  P*\n","*****\n","Current score: 70\n","*****\n","* o *\n","*G P*\n","*   *\n","*****\n","Current score: 70\n","*****\n","* oP*\n","*G  *\n","*   *\n","*****\n","Current score: 80\n","*****\n","* P *\n","*oGo*\n","*   *\n","*****\n","Current score: 80\n","*****\n","* GP*\n","*o o*\n","*   *\n","*****\n","Current score: 90\n","*****\n","*  G*\n","*o P*\n","*   *\n","*****\n","Current score: 90\n","*****\n","* G *\n","*oP *\n","*   *\n","*****\n","Current score: 100\n","*****\n","*  G*\n","*P o*\n","*  o*\n","*****\n","Current score: 100\n","*****\n","* G *\n","* Po*\n","*  o*\n","*****\n","Current score: 110\n","*****\n","*  G*\n","*  P*\n","*  o*\n","*****\n","Current score: 120\n","*****\n","*   *\n","* oG*\n","*o P*\n","*****\n"]}],"source":["sarsa_agent.test_agent()"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1656132364358,"user":{"displayName":"Venkata Datta Sai Nimmaturi","userId":"09700045309629374931"},"user_tz":-330},"id":"nIwQ37ayCOty"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOct2rDONVlwEtBqS/IaC1t","collapsed_sections":[],"name":"Pacman sarsa & qfunc RL.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
